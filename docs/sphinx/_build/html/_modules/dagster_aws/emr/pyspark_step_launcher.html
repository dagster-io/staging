
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>dagster_aws.emr.pyspark_step_launcher &#8212; Dagster</title>
    <link rel="stylesheet" href="../../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
 
<link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />


<meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
    <div class="documentwrapper">
        <div class="bodywrapper">
            <div class="related top">
                &nbsp;
<nav id="rellinks">
    <ul>
        <li>
            <a href="/" title="Home">Home</a>
        </li>
    </ul>
</nav>
            </div>
            

            

            <div class="body" role="main">
                
  <h1>Source code for dagster_aws.emr.pyspark_step_launcher</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">from</span> <span class="nn">botocore.exceptions</span> <span class="kn">import</span> <span class="n">ClientError</span>
<span class="kn">from</span> <span class="nn">dagster</span> <span class="kn">import</span> <span class="n">Field</span><span class="p">,</span> <span class="n">StringSource</span><span class="p">,</span> <span class="n">check</span><span class="p">,</span> <span class="n">resource</span>
<span class="kn">from</span> <span class="nn">dagster.core.definitions.step_launcher</span> <span class="kn">import</span> <span class="n">StepLauncher</span>
<span class="kn">from</span> <span class="nn">dagster.core.errors</span> <span class="kn">import</span> <span class="n">raise_execution_interrupts</span>
<span class="kn">from</span> <span class="nn">dagster.core.events</span> <span class="kn">import</span> <span class="n">log_step_event</span>
<span class="kn">from</span> <span class="nn">dagster.core.execution.plan.external_step</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">PICKLED_EVENTS_FILE_NAME</span><span class="p">,</span>
    <span class="n">PICKLED_STEP_RUN_REF_FILE_NAME</span><span class="p">,</span>
    <span class="n">step_context_to_step_run_ref</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">dagster_aws.emr</span> <span class="kn">import</span> <span class="n">EmrError</span><span class="p">,</span> <span class="n">EmrJobRunner</span><span class="p">,</span> <span class="n">emr_step_main</span>
<span class="kn">from</span> <span class="nn">dagster_aws.emr.configs_spark</span> <span class="kn">import</span> <span class="n">spark_config</span> <span class="k">as</span> <span class="n">get_spark_config</span>
<span class="kn">from</span> <span class="nn">dagster_aws.utils.mrjob.log4j</span> <span class="kn">import</span> <span class="n">parse_hadoop_log4j_records</span>

<span class="c1"># On EMR, Spark is installed here</span>
<span class="n">EMR_SPARK_HOME</span> <span class="o">=</span> <span class="s2">&quot;/usr/lib/spark/&quot;</span>

<span class="n">CODE_ZIP_NAME</span> <span class="o">=</span> <span class="s2">&quot;code.zip&quot;</span>


<div class="viewcode-block" id="emr_pyspark_step_launcher"><a class="viewcode-back" href="../../../sections/api/apidocs/libraries/dagster_aws.html#dagster_aws.emr.emr_pyspark_step_launcher">[docs]</a><span class="nd">@resource</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;spark_config&quot;</span><span class="p">:</span> <span class="n">get_spark_config</span><span class="p">(),</span>
        <span class="s2">&quot;cluster_id&quot;</span><span class="p">:</span> <span class="n">Field</span><span class="p">(</span>
            <span class="n">StringSource</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Name of the job flow (cluster) on which to execute.&quot;</span>
        <span class="p">),</span>
        <span class="s2">&quot;region_name&quot;</span><span class="p">:</span> <span class="n">Field</span><span class="p">(</span><span class="n">StringSource</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The AWS region that the cluster is in.&quot;</span><span class="p">),</span>
        <span class="s2">&quot;action_on_failure&quot;</span><span class="p">:</span> <span class="n">Field</span><span class="p">(</span>
            <span class="nb">str</span><span class="p">,</span>
            <span class="n">is_required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">default_value</span><span class="o">=</span><span class="s2">&quot;CANCEL_AND_WAIT&quot;</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The EMR action to take when the cluster step fails: &quot;</span>
            <span class="s2">&quot;https://docs.aws.amazon.com/emr/latest/APIReference/API_StepConfig.html&quot;</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="s2">&quot;staging_bucket&quot;</span><span class="p">:</span> <span class="n">Field</span><span class="p">(</span>
            <span class="n">StringSource</span><span class="p">,</span>
            <span class="n">is_required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;S3 bucket to use for passing files between the plan process and EMR &quot;</span>
            <span class="s2">&quot;process.&quot;</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="s2">&quot;staging_prefix&quot;</span><span class="p">:</span> <span class="n">Field</span><span class="p">(</span>
            <span class="n">StringSource</span><span class="p">,</span>
            <span class="n">is_required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">default_value</span><span class="o">=</span><span class="s2">&quot;emr_staging&quot;</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;S3 key prefix inside the staging_bucket to use for files passed the plan &quot;</span>
            <span class="s2">&quot;process and EMR process&quot;</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="s2">&quot;wait_for_logs&quot;</span><span class="p">:</span> <span class="n">Field</span><span class="p">(</span>
            <span class="nb">bool</span><span class="p">,</span>
            <span class="n">is_required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">default_value</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;If set, the system will wait for EMR logs to appear on S3. Note that logs &quot;</span>
            <span class="s2">&quot;are copied every 5 minutes, so enabling this will add several minutes to the job &quot;</span>
            <span class="s2">&quot;runtime.&quot;</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="s2">&quot;local_pipeline_package_path&quot;</span><span class="p">:</span> <span class="n">Field</span><span class="p">(</span>
            <span class="n">StringSource</span><span class="p">,</span>
            <span class="n">is_required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Absolute path to the package that contains the pipeline definition(s) &quot;</span>
            <span class="s2">&quot;whose steps will execute remotely on EMR. This is a path on the local fileystem of &quot;</span>
            <span class="s2">&quot;the process executing the pipeline. The expectation is that this package will also be &quot;</span>
            <span class="s2">&quot;available on the python path of the launched process running the Spark step on EMR, &quot;</span>
            <span class="s2">&quot;either deployed on step launch via the deploy_pipeline_package option, referenced on &quot;</span>
            <span class="s2">&quot;s3 via the s3_pipeline_package_path option, or installed on the cluster via bootstrap &quot;</span>
            <span class="s2">&quot;actions.&quot;</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="s2">&quot;deploy_local_pipeline_package&quot;</span><span class="p">:</span> <span class="n">Field</span><span class="p">(</span>
            <span class="nb">bool</span><span class="p">,</span>
            <span class="n">default_value</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">is_required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;If set, before every step run, the launcher will zip up all the code in &quot;</span>
            <span class="s2">&quot;local_pipeline_package_path, upload it to s3, and pass it to spark-submit&#39;s &quot;</span>
            <span class="s2">&quot;--py-files option. This gives the remote process access to up-to-date user code. &quot;</span>
            <span class="s2">&quot;If not set, the assumption is that some other mechanism is used for distributing code &quot;</span>
            <span class="s2">&quot;to the EMR cluster. If this option is set to True, s3_pipeline_package_path should &quot;</span>
            <span class="s2">&quot;not also be set.&quot;</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="s2">&quot;s3_pipeline_package_path&quot;</span><span class="p">:</span> <span class="n">Field</span><span class="p">(</span>
            <span class="n">StringSource</span><span class="p">,</span>
            <span class="n">is_required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;If set, this path will be passed to the --py-files option of spark-submit. &quot;</span>
            <span class="s2">&quot;This should usually be a path to a zip file.  If this option is set, &quot;</span>
            <span class="s2">&quot;deploy_local_pipeline_package should not be set to True.&quot;</span><span class="p">,</span>
        <span class="p">),</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">emr_pyspark_step_launcher</span><span class="p">(</span><span class="n">context</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">EmrPySparkStepLauncher</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="o">.</span><span class="n">resource_config</span><span class="p">)</span></div>


<span class="n">emr_pyspark_step_launcher</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="s2">&quot;- **&quot;</span> <span class="o">+</span> <span class="n">option</span> <span class="o">+</span> <span class="s2">&quot;**: &quot;</span> <span class="o">+</span> <span class="p">(</span><span class="n">field</span><span class="o">.</span><span class="n">description</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">option</span><span class="p">,</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">emr_pyspark_step_launcher</span><span class="o">.</span><span class="n">config_schema</span><span class="o">.</span><span class="n">config_type</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
<span class="p">)</span>


<span class="k">class</span> <span class="nc">EmrPySparkStepLauncher</span><span class="p">(</span><span class="n">StepLauncher</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">region_name</span><span class="p">,</span>
        <span class="n">staging_bucket</span><span class="p">,</span>
        <span class="n">staging_prefix</span><span class="p">,</span>
        <span class="n">wait_for_logs</span><span class="p">,</span>
        <span class="n">action_on_failure</span><span class="p">,</span>
        <span class="n">cluster_id</span><span class="p">,</span>
        <span class="n">spark_config</span><span class="p">,</span>
        <span class="n">local_pipeline_package_path</span><span class="p">,</span>
        <span class="n">deploy_local_pipeline_package</span><span class="p">,</span>
        <span class="n">s3_pipeline_package_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">region_name</span> <span class="o">=</span> <span class="n">check</span><span class="o">.</span><span class="n">str_param</span><span class="p">(</span><span class="n">region_name</span><span class="p">,</span> <span class="s2">&quot;region_name&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">staging_bucket</span> <span class="o">=</span> <span class="n">check</span><span class="o">.</span><span class="n">str_param</span><span class="p">(</span><span class="n">staging_bucket</span><span class="p">,</span> <span class="s2">&quot;staging_bucket&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">staging_prefix</span> <span class="o">=</span> <span class="n">check</span><span class="o">.</span><span class="n">str_param</span><span class="p">(</span><span class="n">staging_prefix</span><span class="p">,</span> <span class="s2">&quot;staging_prefix&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait_for_logs</span> <span class="o">=</span> <span class="n">check</span><span class="o">.</span><span class="n">bool_param</span><span class="p">(</span><span class="n">wait_for_logs</span><span class="p">,</span> <span class="s2">&quot;wait_for_logs&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_on_failure</span> <span class="o">=</span> <span class="n">check</span><span class="o">.</span><span class="n">str_param</span><span class="p">(</span><span class="n">action_on_failure</span><span class="p">,</span> <span class="s2">&quot;action_on_failure&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cluster_id</span> <span class="o">=</span> <span class="n">check</span><span class="o">.</span><span class="n">str_param</span><span class="p">(</span><span class="n">cluster_id</span><span class="p">,</span> <span class="s2">&quot;cluster_id&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spark_config</span> <span class="o">=</span> <span class="n">spark_config</span>

        <span class="n">check</span><span class="o">.</span><span class="n">invariant</span><span class="p">(</span>
            <span class="ow">not</span> <span class="n">deploy_local_pipeline_package</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">s3_pipeline_package_path</span><span class="p">,</span>
            <span class="s2">&quot;If deploy_local_pipeline_package is set to True, s3_pipeline_package_path should not &quot;</span>
            <span class="s2">&quot;also be set.&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">local_pipeline_package_path</span> <span class="o">=</span> <span class="n">check</span><span class="o">.</span><span class="n">str_param</span><span class="p">(</span>
            <span class="n">local_pipeline_package_path</span><span class="p">,</span> <span class="s2">&quot;local_pipeline_package_path&quot;</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deploy_local_pipeline_package</span> <span class="o">=</span> <span class="n">check</span><span class="o">.</span><span class="n">bool_param</span><span class="p">(</span>
            <span class="n">deploy_local_pipeline_package</span><span class="p">,</span> <span class="s2">&quot;deploy_local_pipeline_package&quot;</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s3_pipeline_package_path</span> <span class="o">=</span> <span class="n">check</span><span class="o">.</span><span class="n">opt_str_param</span><span class="p">(</span>
            <span class="n">s3_pipeline_package_path</span><span class="p">,</span> <span class="s2">&quot;s3_pipeline_package_path&quot;</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">emr_job_runner</span> <span class="o">=</span> <span class="n">EmrJobRunner</span><span class="p">(</span><span class="n">region</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">region_name</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_post_artifacts</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log</span><span class="p">,</span> <span class="n">step_run_ref</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Synchronize the step run ref and pyspark code to an S3 staging bucket for use on EMR.</span>

<span class="sd">        For the zip file, consider the following toy example:</span>

<span class="sd">            # Folder: my_pyspark_project/</span>
<span class="sd">            # a.py</span>
<span class="sd">            def foo():</span>
<span class="sd">                print(1)</span>

<span class="sd">            # b.py</span>
<span class="sd">            def bar():</span>
<span class="sd">                print(2)</span>

<span class="sd">            # main.py</span>
<span class="sd">            from a import foo</span>
<span class="sd">            from b import bar</span>

<span class="sd">            foo()</span>
<span class="sd">            bar()</span>

<span class="sd">        This will zip up `my_pyspark_project/` as `my_pyspark_project.zip`. Then, when running</span>
<span class="sd">        `spark-submit --py-files my_pyspark_project.zip emr_step_main.py` on EMR this will</span>
<span class="sd">        print 1, 2.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">dagster_pyspark.utils</span> <span class="kn">import</span> <span class="n">build_pyspark_zip</span>

        <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">temp_dir</span><span class="p">:</span>
            <span class="n">s3</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s2">&quot;s3&quot;</span><span class="p">,</span> <span class="n">region_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">region_name</span><span class="p">)</span>

            <span class="c1"># Upload step run ref</span>
            <span class="k">def</span> <span class="nf">_upload_file_to_s3</span><span class="p">(</span><span class="n">local_path</span><span class="p">,</span> <span class="n">s3_filename</span><span class="p">):</span>
                <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_artifact_s3_key</span><span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">s3_filename</span><span class="p">)</span>
                <span class="n">s3_uri</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_artifact_s3_uri</span><span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">s3_filename</span><span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="s2">&quot;Uploading file </span><span class="si">{local_path}</span><span class="s2"> to </span><span class="si">{s3_uri}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">local_path</span><span class="o">=</span><span class="n">local_path</span><span class="p">,</span> <span class="n">s3_uri</span><span class="o">=</span><span class="n">s3_uri</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="n">s3</span><span class="o">.</span><span class="n">upload_file</span><span class="p">(</span><span class="n">Filename</span><span class="o">=</span><span class="n">local_path</span><span class="p">,</span> <span class="n">Bucket</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">staging_bucket</span><span class="p">,</span> <span class="n">Key</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>

            <span class="c1"># Upload main file.</span>
            <span class="c1"># The remote Dagster installation should also have the file, but locating it there</span>
            <span class="c1"># could be a pain.</span>
            <span class="n">main_local_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_main_file_local_path</span><span class="p">()</span>
            <span class="n">_upload_file_to_s3</span><span class="p">(</span><span class="n">main_local_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_main_file_name</span><span class="p">())</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">deploy_local_pipeline_package</span><span class="p">:</span>
                <span class="c1"># Zip and upload package containing pipeline</span>
                <span class="n">zip_local_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">temp_dir</span><span class="p">,</span> <span class="n">CODE_ZIP_NAME</span><span class="p">)</span>

                <span class="n">build_pyspark_zip</span><span class="p">(</span><span class="n">zip_local_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_pipeline_package_path</span><span class="p">)</span>
                <span class="n">_upload_file_to_s3</span><span class="p">(</span><span class="n">zip_local_path</span><span class="p">,</span> <span class="n">CODE_ZIP_NAME</span><span class="p">)</span>

            <span class="c1"># Create step run ref pickle file</span>
            <span class="n">step_run_ref_local_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">temp_dir</span><span class="p">,</span> <span class="n">PICKLED_STEP_RUN_REF_FILE_NAME</span><span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">step_run_ref_local_path</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">step_pickle_file</span><span class="p">:</span>
                <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">step_run_ref</span><span class="p">,</span> <span class="n">step_pickle_file</span><span class="p">)</span>

            <span class="n">_upload_file_to_s3</span><span class="p">(</span><span class="n">step_run_ref_local_path</span><span class="p">,</span> <span class="n">PICKLED_STEP_RUN_REF_FILE_NAME</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">launch_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step_context</span><span class="p">,</span> <span class="n">prior_attempts_count</span><span class="p">):</span>
        <span class="n">step_run_ref</span> <span class="o">=</span> <span class="n">step_context_to_step_run_ref</span><span class="p">(</span>
            <span class="n">step_context</span><span class="p">,</span> <span class="n">prior_attempts_count</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_pipeline_package_path</span>
        <span class="p">)</span>

        <span class="n">run_id</span> <span class="o">=</span> <span class="n">step_context</span><span class="o">.</span><span class="n">pipeline_run</span><span class="o">.</span><span class="n">run_id</span>
        <span class="n">log</span> <span class="o">=</span> <span class="n">step_context</span><span class="o">.</span><span class="n">log</span>

        <span class="n">step_key</span> <span class="o">=</span> <span class="n">step_run_ref</span><span class="o">.</span><span class="n">step_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_post_artifacts</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">step_run_ref</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">)</span>

        <span class="n">emr_step_def</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_emr_step_def</span><span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">step_context</span><span class="o">.</span><span class="n">solid</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="n">emr_step_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emr_job_runner</span><span class="o">.</span><span class="n">add_job_flow_steps</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_id</span><span class="p">,</span> <span class="p">[</span><span class="n">emr_step_def</span><span class="p">])[</span>
            <span class="mi">0</span>
        <span class="p">]</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">wait_for_completion_and_log</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">emr_step_id</span><span class="p">,</span> <span class="n">step_context</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">wait_for_completion_and_log</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">emr_step_id</span><span class="p">,</span> <span class="n">step_context</span><span class="p">):</span>
        <span class="n">s3</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">resource</span><span class="p">(</span><span class="s2">&quot;s3&quot;</span><span class="p">,</span> <span class="n">region_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">region_name</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">wait_for_completion</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">s3</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">emr_step_id</span><span class="p">):</span>
                <span class="n">log_step_event</span><span class="p">(</span><span class="n">step_context</span><span class="p">,</span> <span class="n">event</span><span class="p">)</span>
                <span class="k">yield</span> <span class="n">event</span>
        <span class="k">except</span> <span class="n">EmrError</span> <span class="k">as</span> <span class="n">emr_error</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">wait_for_logs</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_log_logs_from_s3</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">emr_step_id</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">emr_error</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">wait_for_logs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_logs_from_s3</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">emr_step_id</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">wait_for_completion</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log</span><span class="p">,</span> <span class="n">s3</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">emr_step_id</span><span class="p">,</span> <span class="n">check_interval</span><span class="o">=</span><span class="mi">15</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; We want to wait for the EMR steps to complete, and while that&#39;s happening, we want to</span>
<span class="sd">        yield any events that have been written to S3 for us by the remote process.</span>
<span class="sd">        After the the EMR steps complete, we want a final chance to fetch events before finishing</span>
<span class="sd">        the step.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">all_events</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># If this is being called within a `capture_interrupts` context, allow interrupts</span>
        <span class="c1"># while waiting for the pyspark execution to complete, so that we can terminate slow or</span>
        <span class="c1"># hanging steps</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">raise_execution_interrupts</span><span class="p">():</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">check_interval</span><span class="p">)</span>  <span class="c1"># AWS rate-limits us if we poll it too often</span>
                <span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emr_job_runner</span><span class="o">.</span><span class="n">is_emr_step_complete</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_id</span><span class="p">,</span> <span class="n">emr_step_id</span><span class="p">)</span>

                <span class="n">all_events_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">read_events</span><span class="p">(</span><span class="n">s3</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_events_new</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_events</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_events</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_events_new</span><span class="p">)):</span>
                    <span class="k">yield</span> <span class="n">all_events_new</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">all_events</span> <span class="o">=</span> <span class="n">all_events_new</span>

    <span class="k">def</span> <span class="nf">read_events</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s3</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">):</span>
        <span class="n">events_s3_obj</span> <span class="o">=</span> <span class="n">s3</span><span class="o">.</span><span class="n">Object</span><span class="p">(</span>  <span class="c1"># pylint: disable=no-member</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">staging_bucket</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_artifact_s3_key</span><span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">PICKLED_EVENTS_FILE_NAME</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">events_data</span> <span class="o">=</span> <span class="n">events_s3_obj</span><span class="o">.</span><span class="n">get</span><span class="p">()[</span><span class="s2">&quot;Body&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">events_data</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">ClientError</span> <span class="k">as</span> <span class="n">ex</span><span class="p">:</span>
            <span class="c1"># The file might not be there yet, which is fine</span>
            <span class="k">if</span> <span class="n">ex</span><span class="o">.</span><span class="n">response</span><span class="p">[</span><span class="s2">&quot;Error&quot;</span><span class="p">][</span><span class="s2">&quot;Code&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;NoSuchKey&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">[]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ex</span>

    <span class="k">def</span> <span class="nf">_log_logs_from_s3</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log</span><span class="p">,</span> <span class="n">emr_step_id</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the logs from the remote PySpark process that EMR posted to S3 and logs</span>
<span class="sd">        them to the given log.&quot;&quot;&quot;</span>
        <span class="n">stdout_log</span><span class="p">,</span> <span class="n">stderr_log</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emr_job_runner</span><span class="o">.</span><span class="n">retrieve_logs_for_step_id</span><span class="p">(</span>
            <span class="n">log</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_id</span><span class="p">,</span> <span class="n">emr_step_id</span>
        <span class="p">)</span>
        <span class="c1"># Since stderr is YARN / Hadoop Log4J output, parse and reformat those log lines for</span>
        <span class="c1"># Dagster&#39;s logging system.</span>
        <span class="n">records</span> <span class="o">=</span> <span class="n">parse_hadoop_log4j_records</span><span class="p">(</span><span class="n">stderr_log</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">records</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">_log</span><span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>
                <span class="n">record</span><span class="o">.</span><span class="n">level</span><span class="p">,</span>
                <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;Spark Driver stderr: &quot;</span><span class="p">,</span> <span class="n">record</span><span class="o">.</span><span class="n">logger</span><span class="p">,</span> <span class="s2">&quot;: &quot;</span><span class="p">,</span> <span class="n">record</span><span class="o">.</span><span class="n">message</span><span class="p">]),</span>
                <span class="p">{},</span>
            <span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Spark Driver stdout: &quot;</span> <span class="o">+</span> <span class="n">stdout_log</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_emr_step_def</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">solid_name</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;From the local Dagster instance, construct EMR steps that will kick off execution on a</span>
<span class="sd">        remote EMR cluster.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">dagster_spark.utils</span> <span class="kn">import</span> <span class="n">flatten_dict</span><span class="p">,</span> <span class="n">format_for_cli</span>

        <span class="n">action_on_failure</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_on_failure</span>

        <span class="c1"># Execute Solid via spark-submit</span>
        <span class="n">conf</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">flatten_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spark_config</span><span class="p">))</span>
        <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;spark.app.name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">conf</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;spark.app.name&quot;</span><span class="p">,</span> <span class="n">solid_name</span><span class="p">)</span>

        <span class="n">check</span><span class="o">.</span><span class="n">invariant</span><span class="p">(</span>
            <span class="n">conf</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;spark.master&quot;</span><span class="p">,</span> <span class="s2">&quot;yarn&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;yarn&quot;</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;spark.master is configured as </span><span class="si">%s</span><span class="s2">; cannot set Spark master on EMR to anything &quot;</span>
            <span class="s1">&#39;other than &quot;yarn&quot;&#39;</span> <span class="o">%</span> <span class="n">conf</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;spark.master&quot;</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="n">command</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[</span>
                <span class="n">EMR_SPARK_HOME</span> <span class="o">+</span> <span class="s2">&quot;bin/spark-submit&quot;</span><span class="p">,</span>
                <span class="s2">&quot;--master&quot;</span><span class="p">,</span>
                <span class="s2">&quot;yarn&quot;</span><span class="p">,</span>
                <span class="s2">&quot;--deploy-mode&quot;</span><span class="p">,</span>
                <span class="n">conf</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;spark.submit.deployMode&quot;</span><span class="p">,</span> <span class="s2">&quot;client&quot;</span><span class="p">),</span>
            <span class="p">]</span>
            <span class="o">+</span> <span class="n">format_for_cli</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">flatten_dict</span><span class="p">(</span><span class="n">conf</span><span class="p">)))</span>
            <span class="o">+</span> <span class="p">[</span>
                <span class="s2">&quot;--py-files&quot;</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_artifact_s3_uri</span><span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">CODE_ZIP_NAME</span><span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_artifact_s3_uri</span><span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_main_file_name</span><span class="p">()),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">staging_bucket</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_artifact_s3_key</span><span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">PICKLED_STEP_RUN_REF_FILE_NAME</span><span class="p">),</span>
            <span class="p">]</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">EmrJobRunner</span><span class="o">.</span><span class="n">construct_step_dict_for_command</span><span class="p">(</span>
            <span class="s2">&quot;Execute Solid </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">solid_name</span><span class="p">,</span> <span class="n">command</span><span class="p">,</span> <span class="n">action_on_failure</span><span class="o">=</span><span class="n">action_on_failure</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_main_file_name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_main_file_local_path</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">_main_file_local_path</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">emr_step_main</span><span class="o">.</span><span class="vm">__file__</span>

    <span class="k">def</span> <span class="nf">_artifact_s3_uri</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_artifact_s3_key</span><span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
        <span class="k">return</span> <span class="s2">&quot;s3://</span><span class="si">{bucket}</span><span class="s2">/</span><span class="si">{key}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">bucket</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">staging_bucket</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_artifact_s3_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;/&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">staging_prefix</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">step_key</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">filename</span><span class="p">)])</span>
</pre></div>

            </div>
            <div class="related bottom">
                &nbsp;
<nav id="rellinks">
    <ul>
        <li>
            <a href="/" title="Home">Home</a>
        </li>
    </ul>
</nav>
            </div>
            
        </div>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><h3><a href="../../../index.html">Dagster</a></h3>

<div id="searchbox" style="display: none" role="search">
  <h2 id="searchlabel">Search</h2>
  <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
  </div>
</div>
<script type="text/javascript">
  $("#searchbox").show(0);
</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>


  </body>
</html>