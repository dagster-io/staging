{"parents": [{"link": "../../", "title": "Module code"}], "title": "dagster_spark.configs", "body": "<h1>Source code for dagster_spark.configs</h1><div class=\"highlight\"><pre>\n<span></span><span class=\"sd\">&quot;&quot;&quot;Spark Configuration</span>\n\n<span class=\"sd\">In this file we define the key configuration parameters for submitting Spark jobs. Spark can be run</span>\n<span class=\"sd\">in a variety of deployment contexts. See the Spark documentation at</span>\n<span class=\"sd\">https://spark.apache.org/docs/latest/submitting-applications.html for a more in-depth summary of</span>\n<span class=\"sd\">Spark deployment contexts and configuration.</span>\n<span class=\"sd\">&quot;&quot;&quot;</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dagster</span> <span class=\"kn\">import</span> <span class=\"n\">Field</span><span class=\"p\">,</span> <span class=\"n\">StringSource</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">.configs_spark</span> <span class=\"kn\">import</span> <span class=\"n\">spark_config</span>\n<span class=\"kn\">from</span> <span class=\"nn\">.types</span> <span class=\"kn\">import</span> <span class=\"n\">SparkDeployMode</span>\n\n\n<div class=\"viewcode-block\" id=\"define_spark_config\"><a class=\"viewcode-back\" href=\"../../../sections/api/apidocs/libraries/dagster_spark/#dagster_spark.define_spark_config\">[docs]</a><span class=\"k\">def</span> <span class=\"nf\">define_spark_config</span><span class=\"p\">():</span>\n    <span class=\"sd\">&quot;&quot;&quot;Spark configuration.</span>\n\n<span class=\"sd\">    See the Spark documentation for reference:</span>\n<span class=\"sd\">        https://spark.apache.org/docs/latest/submitting-applications.html</span>\n<span class=\"sd\">    &quot;&quot;&quot;</span>\n\n    <span class=\"n\">master_url</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">(</span>\n        <span class=\"n\">StringSource</span><span class=\"p\">,</span>\n        <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;The master URL for the cluster (e.g. spark://23.195.26.187:7077)&quot;</span><span class=\"p\">,</span>\n        <span class=\"n\">is_required</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"n\">deploy_mode</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">(</span>\n        <span class=\"n\">SparkDeployMode</span><span class=\"p\">,</span>\n        <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;&quot;&quot;Whether to deploy your driver on the worker nodes (cluster) or locally as an</span>\n<span class=\"s2\">        external client (client) (default: client). A common deployment strategy is to submit your</span>\n<span class=\"s2\">        application from a gateway machine that is physically co-located with your worker machines</span>\n<span class=\"s2\">        (e.g. Master node in a standalone EC2 cluster). In this setup, client mode is appropriate.</span>\n<span class=\"s2\">        In client mode, the driver is launched directly within the spark-submit process which acts</span>\n<span class=\"s2\">        as a client to the cluster. The input and output of the application is attached to the</span>\n<span class=\"s2\">        console. Thus, this mode is especially suitable for applications that involve the REPL (e.g.</span>\n<span class=\"s2\">        Spark shell).&quot;&quot;&quot;</span><span class=\"p\">,</span>\n        <span class=\"n\">is_required</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"n\">application_jar</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">(</span>\n        <span class=\"n\">StringSource</span><span class=\"p\">,</span>\n        <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;&quot;&quot;Path to a bundled jar including your application and all</span>\n<span class=\"s2\">                        dependencies. The URL must be globally visible inside of your cluster, for</span>\n<span class=\"s2\">                        instance, an hdfs:// path or a file:// path that is present on all nodes.</span>\n<span class=\"s2\">                        &quot;&quot;&quot;</span><span class=\"p\">,</span>\n        <span class=\"n\">is_required</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"n\">application_arguments</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">(</span>\n        <span class=\"n\">StringSource</span><span class=\"p\">,</span>\n        <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;Arguments passed to the main method of your main class, if any&quot;</span><span class=\"p\">,</span>\n        <span class=\"n\">is_required</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"n\">spark_home</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">(</span>\n        <span class=\"n\">StringSource</span><span class=\"p\">,</span>\n        <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;The path to your spark installation. Defaults to $SPARK_HOME at runtime if not provided.&quot;</span><span class=\"p\">,</span>\n        <span class=\"n\">is_required</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"k\">return</span> <span class=\"p\">{</span>\n        <span class=\"s2\">&quot;master_url&quot;</span><span class=\"p\">:</span> <span class=\"n\">master_url</span><span class=\"p\">,</span>\n        <span class=\"s2\">&quot;deploy_mode&quot;</span><span class=\"p\">:</span> <span class=\"n\">deploy_mode</span><span class=\"p\">,</span>\n        <span class=\"s2\">&quot;application_jar&quot;</span><span class=\"p\">:</span> <span class=\"n\">application_jar</span><span class=\"p\">,</span>\n        <span class=\"s2\">&quot;spark_conf&quot;</span><span class=\"p\">:</span> <span class=\"n\">spark_config</span><span class=\"p\">(),</span>\n        <span class=\"s2\">&quot;spark_home&quot;</span><span class=\"p\">:</span> <span class=\"n\">spark_home</span><span class=\"p\">,</span>\n        <span class=\"s2\">&quot;application_arguments&quot;</span><span class=\"p\">:</span> <span class=\"n\">application_arguments</span><span class=\"p\">,</span>\n    <span class=\"p\">}</span></div>\n</pre></div>", "current_page_name": "_modules/dagster_spark/configs", "sidebars": ["globaltoc.html", "searchbox.html"], "customsidebar": null, "alabaster_version": "0.7.12"}