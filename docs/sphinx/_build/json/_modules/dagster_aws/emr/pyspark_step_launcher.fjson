{"parents": [{"link": "../../../", "title": "Module code"}], "title": "dagster_aws.emr.pyspark_step_launcher", "body": "<h1>Source code for dagster_aws.emr.pyspark_step_launcher</h1><div class=\"highlight\"><pre>\n<span></span><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pickle</span>\n<span class=\"kn\">import</span> <span class=\"nn\">time</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">boto3</span>\n<span class=\"kn\">from</span> <span class=\"nn\">botocore.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">ClientError</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dagster</span> <span class=\"kn\">import</span> <span class=\"n\">Field</span><span class=\"p\">,</span> <span class=\"n\">StringSource</span><span class=\"p\">,</span> <span class=\"n\">check</span><span class=\"p\">,</span> <span class=\"n\">resource</span><span class=\"p\">,</span> <span class=\"n\">seven</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dagster.core.definitions.step_launcher</span> <span class=\"kn\">import</span> <span class=\"n\">StepLauncher</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dagster.core.events</span> <span class=\"kn\">import</span> <span class=\"n\">log_step_event</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dagster.core.execution.plan.external_step</span> <span class=\"kn\">import</span> <span class=\"p\">(</span>\n    <span class=\"n\">PICKLED_EVENTS_FILE_NAME</span><span class=\"p\">,</span>\n    <span class=\"n\">PICKLED_STEP_RUN_REF_FILE_NAME</span><span class=\"p\">,</span>\n    <span class=\"n\">step_context_to_step_run_ref</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dagster.utils</span> <span class=\"kn\">import</span> <span class=\"n\">raise_interrupts_immediately</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dagster_aws.emr</span> <span class=\"kn\">import</span> <span class=\"n\">EmrError</span><span class=\"p\">,</span> <span class=\"n\">EmrJobRunner</span><span class=\"p\">,</span> <span class=\"n\">emr_step_main</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dagster_aws.emr.configs_spark</span> <span class=\"kn\">import</span> <span class=\"n\">spark_config</span> <span class=\"k\">as</span> <span class=\"n\">get_spark_config</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dagster_aws.utils.mrjob.log4j</span> <span class=\"kn\">import</span> <span class=\"n\">parse_hadoop_log4j_records</span>\n\n<span class=\"c1\"># On EMR, Spark is installed here</span>\n<span class=\"n\">EMR_SPARK_HOME</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;/usr/lib/spark/&quot;</span>\n\n<span class=\"n\">CODE_ZIP_NAME</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;code.zip&quot;</span>\n\n\n<div class=\"viewcode-block\" id=\"emr_pyspark_step_launcher\"><a class=\"viewcode-back\" href=\"../../../../sections/api/apidocs/libraries/dagster_aws/#dagster_aws.emr.emr_pyspark_step_launcher\">[docs]</a><span class=\"nd\">@resource</span><span class=\"p\">(</span>\n    <span class=\"p\">{</span>\n        <span class=\"s2\">&quot;spark_config&quot;</span><span class=\"p\">:</span> <span class=\"n\">get_spark_config</span><span class=\"p\">(),</span>\n        <span class=\"s2\">&quot;cluster_id&quot;</span><span class=\"p\">:</span> <span class=\"n\">Field</span><span class=\"p\">(</span>\n            <span class=\"n\">StringSource</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;Name of the job flow (cluster) on which to execute.&quot;</span>\n        <span class=\"p\">),</span>\n        <span class=\"s2\">&quot;region_name&quot;</span><span class=\"p\">:</span> <span class=\"n\">Field</span><span class=\"p\">(</span><span class=\"n\">StringSource</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;The AWS region that the cluster is in.&quot;</span><span class=\"p\">),</span>\n        <span class=\"s2\">&quot;action_on_failure&quot;</span><span class=\"p\">:</span> <span class=\"n\">Field</span><span class=\"p\">(</span>\n            <span class=\"nb\">str</span><span class=\"p\">,</span>\n            <span class=\"n\">is_required</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n            <span class=\"n\">default_value</span><span class=\"o\">=</span><span class=\"s2\">&quot;CANCEL_AND_WAIT&quot;</span><span class=\"p\">,</span>\n            <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;The EMR action to take when the cluster step fails: &quot;</span>\n            <span class=\"s2\">&quot;https://docs.aws.amazon.com/emr/latest/APIReference/API_StepConfig.html&quot;</span><span class=\"p\">,</span>\n        <span class=\"p\">),</span>\n        <span class=\"s2\">&quot;staging_bucket&quot;</span><span class=\"p\">:</span> <span class=\"n\">Field</span><span class=\"p\">(</span>\n            <span class=\"n\">StringSource</span><span class=\"p\">,</span>\n            <span class=\"n\">is_required</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n            <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;S3 bucket to use for passing files between the plan process and EMR &quot;</span>\n            <span class=\"s2\">&quot;process.&quot;</span><span class=\"p\">,</span>\n        <span class=\"p\">),</span>\n        <span class=\"s2\">&quot;staging_prefix&quot;</span><span class=\"p\">:</span> <span class=\"n\">Field</span><span class=\"p\">(</span>\n            <span class=\"n\">StringSource</span><span class=\"p\">,</span>\n            <span class=\"n\">is_required</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n            <span class=\"n\">default_value</span><span class=\"o\">=</span><span class=\"s2\">&quot;emr_staging&quot;</span><span class=\"p\">,</span>\n            <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;S3 key prefix inside the staging_bucket to use for files passed the plan &quot;</span>\n            <span class=\"s2\">&quot;process and EMR process&quot;</span><span class=\"p\">,</span>\n        <span class=\"p\">),</span>\n        <span class=\"s2\">&quot;wait_for_logs&quot;</span><span class=\"p\">:</span> <span class=\"n\">Field</span><span class=\"p\">(</span>\n            <span class=\"nb\">bool</span><span class=\"p\">,</span>\n            <span class=\"n\">is_required</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n            <span class=\"n\">default_value</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n            <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;If set, the system will wait for EMR logs to appear on S3. Note that logs &quot;</span>\n            <span class=\"s2\">&quot;are copied every 5 minutes, so enabling this will add several minutes to the job &quot;</span>\n            <span class=\"s2\">&quot;runtime.&quot;</span><span class=\"p\">,</span>\n        <span class=\"p\">),</span>\n        <span class=\"s2\">&quot;local_pipeline_package_path&quot;</span><span class=\"p\">:</span> <span class=\"n\">Field</span><span class=\"p\">(</span>\n            <span class=\"n\">StringSource</span><span class=\"p\">,</span>\n            <span class=\"n\">is_required</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n            <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;Absolute path to the package that contains the pipeline definition(s) &quot;</span>\n            <span class=\"s2\">&quot;whose steps will execute remotely on EMR. This is a path on the local fileystem of &quot;</span>\n            <span class=\"s2\">&quot;the process executing the pipeline. The expectation is that this package will also be &quot;</span>\n            <span class=\"s2\">&quot;available on the python path of the launched process running the Spark step on EMR, &quot;</span>\n            <span class=\"s2\">&quot;either deployed on step launch via the deploy_pipeline_package option, referenced on &quot;</span>\n            <span class=\"s2\">&quot;s3 via the s3_pipeline_package_path option, or installed on the cluster via bootstrap &quot;</span>\n            <span class=\"s2\">&quot;actions.&quot;</span><span class=\"p\">,</span>\n        <span class=\"p\">),</span>\n        <span class=\"s2\">&quot;deploy_local_pipeline_package&quot;</span><span class=\"p\">:</span> <span class=\"n\">Field</span><span class=\"p\">(</span>\n            <span class=\"nb\">bool</span><span class=\"p\">,</span>\n            <span class=\"n\">default_value</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n            <span class=\"n\">is_required</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n            <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;If set, before every step run, the launcher will zip up all the code in &quot;</span>\n            <span class=\"s2\">&quot;local_pipeline_package_path, upload it to s3, and pass it to spark-submit&#39;s &quot;</span>\n            <span class=\"s2\">&quot;--py-files option. This gives the remote process access to up-to-date user code. &quot;</span>\n            <span class=\"s2\">&quot;If not set, the assumption is that some other mechanism is used for distributing code &quot;</span>\n            <span class=\"s2\">&quot;to the EMR cluster. If this option is set to True, s3_pipeline_package_path should &quot;</span>\n            <span class=\"s2\">&quot;not also be set.&quot;</span><span class=\"p\">,</span>\n        <span class=\"p\">),</span>\n        <span class=\"s2\">&quot;s3_pipeline_package_path&quot;</span><span class=\"p\">:</span> <span class=\"n\">Field</span><span class=\"p\">(</span>\n            <span class=\"n\">StringSource</span><span class=\"p\">,</span>\n            <span class=\"n\">is_required</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n            <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;If set, this path will be passed to the --py-files option of spark-submit. &quot;</span>\n            <span class=\"s2\">&quot;This should usually be a path to a zip file.  If this option is set, &quot;</span>\n            <span class=\"s2\">&quot;deploy_local_pipeline_package should not be set to True.&quot;</span><span class=\"p\">,</span>\n        <span class=\"p\">),</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">)</span>\n<span class=\"k\">def</span> <span class=\"nf\">emr_pyspark_step_launcher</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">EmrPySparkStepLauncher</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">context</span><span class=\"o\">.</span><span class=\"n\">resource_config</span><span class=\"p\">)</span></div>\n\n\n<span class=\"n\">emr_pyspark_step_launcher</span><span class=\"o\">.</span><span class=\"vm\">__doc__</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;</span><span class=\"se\">\\n</span><span class=\"s2\">&quot;</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span>\n    <span class=\"s2\">&quot;- **&quot;</span> <span class=\"o\">+</span> <span class=\"n\">option</span> <span class=\"o\">+</span> <span class=\"s2\">&quot;**: &quot;</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">field</span><span class=\"o\">.</span><span class=\"n\">description</span> <span class=\"ow\">or</span> <span class=\"s2\">&quot;&quot;</span><span class=\"p\">)</span>\n    <span class=\"k\">for</span> <span class=\"n\">option</span><span class=\"p\">,</span> <span class=\"n\">field</span> <span class=\"ow\">in</span> <span class=\"n\">emr_pyspark_step_launcher</span><span class=\"o\">.</span><span class=\"n\">config_schema</span><span class=\"o\">.</span><span class=\"n\">config_type</span><span class=\"o\">.</span><span class=\"n\">fields</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()</span>\n<span class=\"p\">)</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">EmrPySparkStepLauncher</span><span class=\"p\">(</span><span class=\"n\">StepLauncher</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span>\n        <span class=\"bp\">self</span><span class=\"p\">,</span>\n        <span class=\"n\">region_name</span><span class=\"p\">,</span>\n        <span class=\"n\">staging_bucket</span><span class=\"p\">,</span>\n        <span class=\"n\">staging_prefix</span><span class=\"p\">,</span>\n        <span class=\"n\">wait_for_logs</span><span class=\"p\">,</span>\n        <span class=\"n\">action_on_failure</span><span class=\"p\">,</span>\n        <span class=\"n\">cluster_id</span><span class=\"p\">,</span>\n        <span class=\"n\">spark_config</span><span class=\"p\">,</span>\n        <span class=\"n\">local_pipeline_package_path</span><span class=\"p\">,</span>\n        <span class=\"n\">deploy_local_pipeline_package</span><span class=\"p\">,</span>\n        <span class=\"n\">s3_pipeline_package_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n    <span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">region_name</span> <span class=\"o\">=</span> <span class=\"n\">check</span><span class=\"o\">.</span><span class=\"n\">str_param</span><span class=\"p\">(</span><span class=\"n\">region_name</span><span class=\"p\">,</span> <span class=\"s2\">&quot;region_name&quot;</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">staging_bucket</span> <span class=\"o\">=</span> <span class=\"n\">check</span><span class=\"o\">.</span><span class=\"n\">str_param</span><span class=\"p\">(</span><span class=\"n\">staging_bucket</span><span class=\"p\">,</span> <span class=\"s2\">&quot;staging_bucket&quot;</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">staging_prefix</span> <span class=\"o\">=</span> <span class=\"n\">check</span><span class=\"o\">.</span><span class=\"n\">str_param</span><span class=\"p\">(</span><span class=\"n\">staging_prefix</span><span class=\"p\">,</span> <span class=\"s2\">&quot;staging_prefix&quot;</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">wait_for_logs</span> <span class=\"o\">=</span> <span class=\"n\">check</span><span class=\"o\">.</span><span class=\"n\">bool_param</span><span class=\"p\">(</span><span class=\"n\">wait_for_logs</span><span class=\"p\">,</span> <span class=\"s2\">&quot;wait_for_logs&quot;</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">action_on_failure</span> <span class=\"o\">=</span> <span class=\"n\">check</span><span class=\"o\">.</span><span class=\"n\">str_param</span><span class=\"p\">(</span><span class=\"n\">action_on_failure</span><span class=\"p\">,</span> <span class=\"s2\">&quot;action_on_failure&quot;</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cluster_id</span> <span class=\"o\">=</span> <span class=\"n\">check</span><span class=\"o\">.</span><span class=\"n\">str_param</span><span class=\"p\">(</span><span class=\"n\">cluster_id</span><span class=\"p\">,</span> <span class=\"s2\">&quot;cluster_id&quot;</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">spark_config</span> <span class=\"o\">=</span> <span class=\"n\">spark_config</span>\n\n        <span class=\"n\">check</span><span class=\"o\">.</span><span class=\"n\">invariant</span><span class=\"p\">(</span>\n            <span class=\"ow\">not</span> <span class=\"n\">deploy_local_pipeline_package</span> <span class=\"ow\">or</span> <span class=\"ow\">not</span> <span class=\"n\">s3_pipeline_package_path</span><span class=\"p\">,</span>\n            <span class=\"s2\">&quot;If deploy_local_pipeline_package is set to True, s3_pipeline_package_path should not &quot;</span>\n            <span class=\"s2\">&quot;also be set.&quot;</span><span class=\"p\">,</span>\n        <span class=\"p\">)</span>\n\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">local_pipeline_package_path</span> <span class=\"o\">=</span> <span class=\"n\">check</span><span class=\"o\">.</span><span class=\"n\">str_param</span><span class=\"p\">(</span>\n            <span class=\"n\">local_pipeline_package_path</span><span class=\"p\">,</span> <span class=\"s2\">&quot;local_pipeline_package_path&quot;</span>\n        <span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">deploy_local_pipeline_package</span> <span class=\"o\">=</span> <span class=\"n\">check</span><span class=\"o\">.</span><span class=\"n\">bool_param</span><span class=\"p\">(</span>\n            <span class=\"n\">deploy_local_pipeline_package</span><span class=\"p\">,</span> <span class=\"s2\">&quot;deploy_local_pipeline_package&quot;</span>\n        <span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">s3_pipeline_package_path</span> <span class=\"o\">=</span> <span class=\"n\">check</span><span class=\"o\">.</span><span class=\"n\">opt_str_param</span><span class=\"p\">(</span>\n            <span class=\"n\">s3_pipeline_package_path</span><span class=\"p\">,</span> <span class=\"s2\">&quot;s3_pipeline_package_path&quot;</span>\n        <span class=\"p\">)</span>\n\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">emr_job_runner</span> <span class=\"o\">=</span> <span class=\"n\">EmrJobRunner</span><span class=\"p\">(</span><span class=\"n\">region</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">region_name</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">_post_artifacts</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">log</span><span class=\"p\">,</span> <span class=\"n\">step_run_ref</span><span class=\"p\">,</span> <span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">):</span>\n        <span class=\"sd\">&quot;&quot;&quot;</span>\n<span class=\"sd\">        Synchronize the step run ref and pyspark code to an S3 staging bucket for use on EMR.</span>\n\n<span class=\"sd\">        For the zip file, consider the following toy example:</span>\n\n<span class=\"sd\">            # Folder: my_pyspark_project/</span>\n<span class=\"sd\">            # a.py</span>\n<span class=\"sd\">            def foo():</span>\n<span class=\"sd\">                print(1)</span>\n\n<span class=\"sd\">            # b.py</span>\n<span class=\"sd\">            def bar():</span>\n<span class=\"sd\">                print(2)</span>\n\n<span class=\"sd\">            # main.py</span>\n<span class=\"sd\">            from a import foo</span>\n<span class=\"sd\">            from b import bar</span>\n\n<span class=\"sd\">            foo()</span>\n<span class=\"sd\">            bar()</span>\n\n<span class=\"sd\">        This will zip up `my_pyspark_project/` as `my_pyspark_project.zip`. Then, when running</span>\n<span class=\"sd\">        `spark-submit --py-files my_pyspark_project.zip emr_step_main.py` on EMR this will</span>\n<span class=\"sd\">        print 1, 2.</span>\n<span class=\"sd\">        &quot;&quot;&quot;</span>\n        <span class=\"kn\">from</span> <span class=\"nn\">dagster_pyspark.utils</span> <span class=\"kn\">import</span> <span class=\"n\">build_pyspark_zip</span>\n\n        <span class=\"k\">with</span> <span class=\"n\">seven</span><span class=\"o\">.</span><span class=\"n\">TemporaryDirectory</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"n\">temp_dir</span><span class=\"p\">:</span>\n            <span class=\"n\">s3</span> <span class=\"o\">=</span> <span class=\"n\">boto3</span><span class=\"o\">.</span><span class=\"n\">client</span><span class=\"p\">(</span><span class=\"s2\">&quot;s3&quot;</span><span class=\"p\">,</span> <span class=\"n\">region_name</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">region_name</span><span class=\"p\">)</span>\n\n            <span class=\"c1\"># Upload step run ref</span>\n            <span class=\"k\">def</span> <span class=\"nf\">_upload_file_to_s3</span><span class=\"p\">(</span><span class=\"n\">local_path</span><span class=\"p\">,</span> <span class=\"n\">s3_filename</span><span class=\"p\">):</span>\n                <span class=\"n\">key</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_artifact_s3_key</span><span class=\"p\">(</span><span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">s3_filename</span><span class=\"p\">)</span>\n                <span class=\"n\">s3_uri</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_artifact_s3_uri</span><span class=\"p\">(</span><span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">s3_filename</span><span class=\"p\">)</span>\n                <span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">debug</span><span class=\"p\">(</span>\n                    <span class=\"s2\">&quot;Uploading file </span><span class=\"si\">{local_path}</span><span class=\"s2\"> to </span><span class=\"si\">{s3_uri}</span><span class=\"s2\">&quot;</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span>\n                        <span class=\"n\">local_path</span><span class=\"o\">=</span><span class=\"n\">local_path</span><span class=\"p\">,</span> <span class=\"n\">s3_uri</span><span class=\"o\">=</span><span class=\"n\">s3_uri</span>\n                    <span class=\"p\">)</span>\n                <span class=\"p\">)</span>\n                <span class=\"n\">s3</span><span class=\"o\">.</span><span class=\"n\">upload_file</span><span class=\"p\">(</span><span class=\"n\">Filename</span><span class=\"o\">=</span><span class=\"n\">local_path</span><span class=\"p\">,</span> <span class=\"n\">Bucket</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">staging_bucket</span><span class=\"p\">,</span> <span class=\"n\">Key</span><span class=\"o\">=</span><span class=\"n\">key</span><span class=\"p\">)</span>\n\n            <span class=\"c1\"># Upload main file.</span>\n            <span class=\"c1\"># The remote Dagster installation should also have the file, but locating it there</span>\n            <span class=\"c1\"># could be a pain.</span>\n            <span class=\"n\">main_local_path</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_main_file_local_path</span><span class=\"p\">()</span>\n            <span class=\"n\">_upload_file_to_s3</span><span class=\"p\">(</span><span class=\"n\">main_local_path</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_main_file_name</span><span class=\"p\">())</span>\n\n            <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">deploy_local_pipeline_package</span><span class=\"p\">:</span>\n                <span class=\"c1\"># Zip and upload package containing pipeline</span>\n                <span class=\"n\">zip_local_path</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">temp_dir</span><span class=\"p\">,</span> <span class=\"n\">CODE_ZIP_NAME</span><span class=\"p\">)</span>\n\n                <span class=\"n\">build_pyspark_zip</span><span class=\"p\">(</span><span class=\"n\">zip_local_path</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">local_pipeline_package_path</span><span class=\"p\">)</span>\n                <span class=\"n\">_upload_file_to_s3</span><span class=\"p\">(</span><span class=\"n\">zip_local_path</span><span class=\"p\">,</span> <span class=\"n\">CODE_ZIP_NAME</span><span class=\"p\">)</span>\n\n            <span class=\"c1\"># Create step run ref pickle file</span>\n            <span class=\"n\">step_run_ref_local_path</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">temp_dir</span><span class=\"p\">,</span> <span class=\"n\">PICKLED_STEP_RUN_REF_FILE_NAME</span><span class=\"p\">)</span>\n            <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">step_run_ref_local_path</span><span class=\"p\">,</span> <span class=\"s2\">&quot;wb&quot;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">step_pickle_file</span><span class=\"p\">:</span>\n                <span class=\"n\">pickle</span><span class=\"o\">.</span><span class=\"n\">dump</span><span class=\"p\">(</span><span class=\"n\">step_run_ref</span><span class=\"p\">,</span> <span class=\"n\">step_pickle_file</span><span class=\"p\">)</span>\n\n            <span class=\"n\">_upload_file_to_s3</span><span class=\"p\">(</span><span class=\"n\">step_run_ref_local_path</span><span class=\"p\">,</span> <span class=\"n\">PICKLED_STEP_RUN_REF_FILE_NAME</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">launch_step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">step_context</span><span class=\"p\">,</span> <span class=\"n\">prior_attempts_count</span><span class=\"p\">):</span>\n        <span class=\"n\">step_run_ref</span> <span class=\"o\">=</span> <span class=\"n\">step_context_to_step_run_ref</span><span class=\"p\">(</span>\n            <span class=\"n\">step_context</span><span class=\"p\">,</span> <span class=\"n\">prior_attempts_count</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">local_pipeline_package_path</span>\n        <span class=\"p\">)</span>\n\n        <span class=\"n\">run_id</span> <span class=\"o\">=</span> <span class=\"n\">step_context</span><span class=\"o\">.</span><span class=\"n\">pipeline_run</span><span class=\"o\">.</span><span class=\"n\">run_id</span>\n        <span class=\"n\">log</span> <span class=\"o\">=</span> <span class=\"n\">step_context</span><span class=\"o\">.</span><span class=\"n\">log</span>\n\n        <span class=\"n\">step_key</span> <span class=\"o\">=</span> <span class=\"n\">step_run_ref</span><span class=\"o\">.</span><span class=\"n\">step_key</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_post_artifacts</span><span class=\"p\">(</span><span class=\"n\">log</span><span class=\"p\">,</span> <span class=\"n\">step_run_ref</span><span class=\"p\">,</span> <span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">)</span>\n\n        <span class=\"n\">emr_step_def</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_get_emr_step_def</span><span class=\"p\">(</span><span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">step_context</span><span class=\"o\">.</span><span class=\"n\">solid</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">)</span>\n        <span class=\"n\">emr_step_id</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">emr_job_runner</span><span class=\"o\">.</span><span class=\"n\">add_job_flow_steps</span><span class=\"p\">(</span><span class=\"n\">log</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cluster_id</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">emr_step_def</span><span class=\"p\">])[</span>\n            <span class=\"mi\">0</span>\n        <span class=\"p\">]</span>\n\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">wait_for_completion_and_log</span><span class=\"p\">(</span><span class=\"n\">log</span><span class=\"p\">,</span> <span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">emr_step_id</span><span class=\"p\">,</span> <span class=\"n\">step_context</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">wait_for_completion_and_log</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">log</span><span class=\"p\">,</span> <span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">emr_step_id</span><span class=\"p\">,</span> <span class=\"n\">step_context</span><span class=\"p\">):</span>\n        <span class=\"n\">s3</span> <span class=\"o\">=</span> <span class=\"n\">boto3</span><span class=\"o\">.</span><span class=\"n\">resource</span><span class=\"p\">(</span><span class=\"s2\">&quot;s3&quot;</span><span class=\"p\">,</span> <span class=\"n\">region_name</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">region_name</span><span class=\"p\">)</span>\n        <span class=\"k\">try</span><span class=\"p\">:</span>\n            <span class=\"k\">for</span> <span class=\"n\">event</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">wait_for_completion</span><span class=\"p\">(</span><span class=\"n\">log</span><span class=\"p\">,</span> <span class=\"n\">s3</span><span class=\"p\">,</span> <span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">emr_step_id</span><span class=\"p\">):</span>\n                <span class=\"n\">log_step_event</span><span class=\"p\">(</span><span class=\"n\">step_context</span><span class=\"p\">,</span> <span class=\"n\">event</span><span class=\"p\">)</span>\n                <span class=\"k\">yield</span> <span class=\"n\">event</span>\n        <span class=\"k\">except</span> <span class=\"n\">EmrError</span> <span class=\"k\">as</span> <span class=\"n\">emr_error</span><span class=\"p\">:</span>\n            <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">wait_for_logs</span><span class=\"p\">:</span>\n                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_log_logs_from_s3</span><span class=\"p\">(</span><span class=\"n\">log</span><span class=\"p\">,</span> <span class=\"n\">emr_step_id</span><span class=\"p\">)</span>\n            <span class=\"k\">raise</span> <span class=\"n\">emr_error</span>\n\n        <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">wait_for_logs</span><span class=\"p\">:</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_log_logs_from_s3</span><span class=\"p\">(</span><span class=\"n\">log</span><span class=\"p\">,</span> <span class=\"n\">emr_step_id</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">wait_for_completion</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">log</span><span class=\"p\">,</span> <span class=\"n\">s3</span><span class=\"p\">,</span> <span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">emr_step_id</span><span class=\"p\">,</span> <span class=\"n\">check_interval</span><span class=\"o\">=</span><span class=\"mi\">15</span><span class=\"p\">):</span>\n        <span class=\"sd\">&quot;&quot;&quot; We want to wait for the EMR steps to complete, and while that&#39;s happening, we want to</span>\n<span class=\"sd\">        yield any events that have been written to S3 for us by the remote process.</span>\n<span class=\"sd\">        After the the EMR steps complete, we want a final chance to fetch events before finishing</span>\n<span class=\"sd\">        the step.</span>\n<span class=\"sd\">        &quot;&quot;&quot;</span>\n        <span class=\"n\">done</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n        <span class=\"n\">all_events</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n        <span class=\"c1\"># If this is being called within a `delay_interrupts` context, allow interrupts</span>\n        <span class=\"c1\"># while waiting for the pyspark execution to complete, so that we can terminate slow or</span>\n        <span class=\"c1\"># hanging steps</span>\n        <span class=\"k\">while</span> <span class=\"ow\">not</span> <span class=\"n\">done</span><span class=\"p\">:</span>\n            <span class=\"k\">with</span> <span class=\"n\">raise_interrupts_immediately</span><span class=\"p\">():</span>\n                <span class=\"n\">time</span><span class=\"o\">.</span><span class=\"n\">sleep</span><span class=\"p\">(</span><span class=\"n\">check_interval</span><span class=\"p\">)</span>  <span class=\"c1\"># AWS rate-limits us if we poll it too often</span>\n                <span class=\"n\">done</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">emr_job_runner</span><span class=\"o\">.</span><span class=\"n\">is_emr_step_complete</span><span class=\"p\">(</span><span class=\"n\">log</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cluster_id</span><span class=\"p\">,</span> <span class=\"n\">emr_step_id</span><span class=\"p\">)</span>\n\n                <span class=\"n\">all_events_new</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">read_events</span><span class=\"p\">(</span><span class=\"n\">s3</span><span class=\"p\">,</span> <span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">)</span>\n\n            <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">all_events_new</span><span class=\"p\">)</span> <span class=\"o\">&gt;</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">all_events</span><span class=\"p\">):</span>\n                <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">all_events</span><span class=\"p\">),</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">all_events_new</span><span class=\"p\">)):</span>\n                    <span class=\"k\">yield</span> <span class=\"n\">all_events_new</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span>\n                <span class=\"n\">all_events</span> <span class=\"o\">=</span> <span class=\"n\">all_events_new</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">read_events</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">s3</span><span class=\"p\">,</span> <span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">):</span>\n        <span class=\"n\">events_s3_obj</span> <span class=\"o\">=</span> <span class=\"n\">s3</span><span class=\"o\">.</span><span class=\"n\">Object</span><span class=\"p\">(</span>  <span class=\"c1\"># pylint: disable=no-member</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">staging_bucket</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_artifact_s3_key</span><span class=\"p\">(</span><span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">PICKLED_EVENTS_FILE_NAME</span><span class=\"p\">)</span>\n        <span class=\"p\">)</span>\n\n        <span class=\"k\">try</span><span class=\"p\">:</span>\n            <span class=\"n\">events_data</span> <span class=\"o\">=</span> <span class=\"n\">events_s3_obj</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()[</span><span class=\"s2\">&quot;Body&quot;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span>\n            <span class=\"k\">return</span> <span class=\"n\">pickle</span><span class=\"o\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">events_data</span><span class=\"p\">)</span>\n        <span class=\"k\">except</span> <span class=\"n\">ClientError</span> <span class=\"k\">as</span> <span class=\"n\">ex</span><span class=\"p\">:</span>\n            <span class=\"c1\"># The file might not be there yet, which is fine</span>\n            <span class=\"k\">if</span> <span class=\"n\">ex</span><span class=\"o\">.</span><span class=\"n\">response</span><span class=\"p\">[</span><span class=\"s2\">&quot;Error&quot;</span><span class=\"p\">][</span><span class=\"s2\">&quot;Code&quot;</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;NoSuchKey&quot;</span><span class=\"p\">:</span>\n                <span class=\"k\">return</span> <span class=\"p\">[]</span>\n            <span class=\"k\">else</span><span class=\"p\">:</span>\n                <span class=\"k\">raise</span> <span class=\"n\">ex</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">_log_logs_from_s3</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">log</span><span class=\"p\">,</span> <span class=\"n\">emr_step_id</span><span class=\"p\">):</span>\n        <span class=\"sd\">&quot;&quot;&quot;Retrieves the logs from the remote PySpark process that EMR posted to S3 and logs</span>\n<span class=\"sd\">        them to the given log.&quot;&quot;&quot;</span>\n        <span class=\"n\">stdout_log</span><span class=\"p\">,</span> <span class=\"n\">stderr_log</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">emr_job_runner</span><span class=\"o\">.</span><span class=\"n\">retrieve_logs_for_step_id</span><span class=\"p\">(</span>\n            <span class=\"n\">log</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cluster_id</span><span class=\"p\">,</span> <span class=\"n\">emr_step_id</span>\n        <span class=\"p\">)</span>\n        <span class=\"c1\"># Since stderr is YARN / Hadoop Log4J output, parse and reformat those log lines for</span>\n        <span class=\"c1\"># Dagster&#39;s logging system.</span>\n        <span class=\"n\">records</span> <span class=\"o\">=</span> <span class=\"n\">parse_hadoop_log4j_records</span><span class=\"p\">(</span><span class=\"n\">stderr_log</span><span class=\"p\">)</span>\n        <span class=\"k\">for</span> <span class=\"n\">record</span> <span class=\"ow\">in</span> <span class=\"n\">records</span><span class=\"p\">:</span>\n            <span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">_log</span><span class=\"p\">(</span>  <span class=\"c1\"># pylint: disable=protected-access</span>\n                <span class=\"n\">record</span><span class=\"o\">.</span><span class=\"n\">level</span><span class=\"p\">,</span>\n                <span class=\"s2\">&quot;&quot;</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">([</span><span class=\"s2\">&quot;Spark Driver stderr: &quot;</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"p\">,</span> <span class=\"s2\">&quot;: &quot;</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"o\">.</span><span class=\"n\">message</span><span class=\"p\">]),</span>\n                <span class=\"p\">{},</span>\n            <span class=\"p\">)</span>\n        <span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">&quot;Spark Driver stdout: &quot;</span> <span class=\"o\">+</span> <span class=\"n\">stdout_log</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">_get_emr_step_def</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">solid_name</span><span class=\"p\">):</span>\n        <span class=\"sd\">&quot;&quot;&quot;From the local Dagster instance, construct EMR steps that will kick off execution on a</span>\n<span class=\"sd\">        remote EMR cluster.</span>\n<span class=\"sd\">        &quot;&quot;&quot;</span>\n        <span class=\"kn\">from</span> <span class=\"nn\">dagster_spark.utils</span> <span class=\"kn\">import</span> <span class=\"n\">flatten_dict</span><span class=\"p\">,</span> <span class=\"n\">format_for_cli</span>\n\n        <span class=\"n\">action_on_failure</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">action_on_failure</span>\n\n        <span class=\"c1\"># Execute Solid via spark-submit</span>\n        <span class=\"n\">conf</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">flatten_dict</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">spark_config</span><span class=\"p\">))</span>\n        <span class=\"n\">conf</span><span class=\"p\">[</span><span class=\"s2\">&quot;spark.app.name&quot;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">conf</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s2\">&quot;spark.app.name&quot;</span><span class=\"p\">,</span> <span class=\"n\">solid_name</span><span class=\"p\">)</span>\n\n        <span class=\"n\">check</span><span class=\"o\">.</span><span class=\"n\">invariant</span><span class=\"p\">(</span>\n            <span class=\"n\">conf</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s2\">&quot;spark.master&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;yarn&quot;</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;yarn&quot;</span><span class=\"p\">,</span>\n            <span class=\"n\">desc</span><span class=\"o\">=</span><span class=\"s2\">&quot;spark.master is configured as </span><span class=\"si\">%s</span><span class=\"s2\">; cannot set Spark master on EMR to anything &quot;</span>\n            <span class=\"s1\">&#39;other than &quot;yarn&quot;&#39;</span> <span class=\"o\">%</span> <span class=\"n\">conf</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s2\">&quot;spark.master&quot;</span><span class=\"p\">),</span>\n        <span class=\"p\">)</span>\n\n        <span class=\"n\">command</span> <span class=\"o\">=</span> <span class=\"p\">(</span>\n            <span class=\"p\">[</span>\n                <span class=\"n\">EMR_SPARK_HOME</span> <span class=\"o\">+</span> <span class=\"s2\">&quot;bin/spark-submit&quot;</span><span class=\"p\">,</span>\n                <span class=\"s2\">&quot;--master&quot;</span><span class=\"p\">,</span>\n                <span class=\"s2\">&quot;yarn&quot;</span><span class=\"p\">,</span>\n                <span class=\"s2\">&quot;--deploy-mode&quot;</span><span class=\"p\">,</span>\n                <span class=\"n\">conf</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s2\">&quot;spark.submit.deployMode&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;client&quot;</span><span class=\"p\">),</span>\n            <span class=\"p\">]</span>\n            <span class=\"o\">+</span> <span class=\"n\">format_for_cli</span><span class=\"p\">(</span><span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">flatten_dict</span><span class=\"p\">(</span><span class=\"n\">conf</span><span class=\"p\">)))</span>\n            <span class=\"o\">+</span> <span class=\"p\">[</span>\n                <span class=\"s2\">&quot;--py-files&quot;</span><span class=\"p\">,</span>\n                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_artifact_s3_uri</span><span class=\"p\">(</span><span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">CODE_ZIP_NAME</span><span class=\"p\">),</span>\n                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_artifact_s3_uri</span><span class=\"p\">(</span><span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_main_file_name</span><span class=\"p\">()),</span>\n                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">staging_bucket</span><span class=\"p\">,</span>\n                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_artifact_s3_key</span><span class=\"p\">(</span><span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">PICKLED_STEP_RUN_REF_FILE_NAME</span><span class=\"p\">),</span>\n            <span class=\"p\">]</span>\n        <span class=\"p\">)</span>\n\n        <span class=\"k\">return</span> <span class=\"n\">EmrJobRunner</span><span class=\"o\">.</span><span class=\"n\">construct_step_dict_for_command</span><span class=\"p\">(</span>\n            <span class=\"s2\">&quot;Execute Solid </span><span class=\"si\">%s</span><span class=\"s2\">&quot;</span> <span class=\"o\">%</span> <span class=\"n\">solid_name</span><span class=\"p\">,</span> <span class=\"n\">command</span><span class=\"p\">,</span> <span class=\"n\">action_on_failure</span><span class=\"o\">=</span><span class=\"n\">action_on_failure</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">_main_file_name</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">basename</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_main_file_local_path</span><span class=\"p\">())</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">_main_file_local_path</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">emr_step_main</span><span class=\"o\">.</span><span class=\"vm\">__file__</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">_artifact_s3_uri</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">filename</span><span class=\"p\">):</span>\n        <span class=\"n\">key</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_artifact_s3_key</span><span class=\"p\">(</span><span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">filename</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"s2\">&quot;s3://</span><span class=\"si\">{bucket}</span><span class=\"s2\">/</span><span class=\"si\">{key}</span><span class=\"s2\">&quot;</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">bucket</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">staging_bucket</span><span class=\"p\">,</span> <span class=\"n\">key</span><span class=\"o\">=</span><span class=\"n\">key</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">_artifact_s3_key</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">filename</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"s2\">&quot;/&quot;</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">([</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">staging_prefix</span><span class=\"p\">,</span> <span class=\"n\">run_id</span><span class=\"p\">,</span> <span class=\"n\">step_key</span><span class=\"p\">,</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">basename</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">)])</span>\n</pre></div>", "current_page_name": "_modules/dagster_aws/emr/pyspark_step_launcher", "sidebars": ["globaltoc.html", "searchbox.html"], "customsidebar": null, "alabaster_version": "0.7.12"}